<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  Bayesian Inference · home
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="description" content="Bayesian Inference 
Bayesian Inference is an approach to statistical inference which utilises Bayes&rsquo; theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:
$$
p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)}
$$
Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:">
<meta name="keywords" content="">



  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Bayesian Inference">
  <meta name="twitter:description" content="Bayesian Inference Bayesian Inference is an approach to statistical inference which utilises Bayes’ theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:
$$ p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)} $$
Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:">

<meta property="og:url" content="https://dwil2444.github.io/posts/bp/">
  <meta property="og:site_name" content="home">
  <meta property="og:title" content="Bayesian Inference">
  <meta property="og:description" content="Bayesian Inference Bayesian Inference is an approach to statistical inference which utilises Bayes’ theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:
$$ p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)} $$
Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2022-05-05T00:00:00+00:00">
    <meta property="article:modified_time" content="2022-05-05T00:00:00+00:00">




<link rel="canonical" href="https://dwil2444.github.io/posts/bp/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.ed30115a76cdaa62f2229e973d5b1c89b2d3dd4b1d9c07a729baad06aa3b0cbe.css" integrity="sha256-7TARWnbNqmLyIp6XPVscibLT3UsdnAenKbqtBqo7DL4=" crossorigin="anonymous" media="screen" />








 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>




<body class="preload-transitions colorscheme-light">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="https://dwil2444.github.io/">
      home
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/about">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/publications">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/teaching">Teaching</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/posts">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/cv.pdf">CV</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://dwil2444.github.io/posts/bp/">
              Bayesian Inference
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-05-05T00:00:00Z">
                May 5, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              3-minute read
            </span>
          </div>
          
          
          
        </div>
      </header>

      <div class="post-content">
        
        <h1 align="center">Bayesian Inference </h1>
<p><strong>Bayesian Inference</strong> is an approach to statistical inference which utilises Bayes&rsquo; theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:</p>
<p>$$
p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)}
$$</p>
<p>Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:</p>
<h5 id="key-terms">
  Key Terms
  <a class="heading-link" href="#key-terms">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h5>
<ul>
<li>
<p><u> Z $\rightarrow$ Hypothesis:</u><br />
<strong>Z</strong> represents any hypothesis whose probability may be affected by data.</p>
</li>
<li>
<p><u> X $\rightarrow$ Evidence:</u><br />
<strong>X</strong> represents new data that was not used in computing <strong>prior</strong> probability.</p>
</li>
<li>
<p><u> P(z) $\rightarrow$ Prior:</u><br />
The <strong>prior</strong> is the estimate of the probability of the hypothesis <strong>z</strong> before the evidence <strong>x</strong> is observed.</p>
</li>
<li>
<p><u> P(x $\mid$ z) $\rightarrow$ Likelihood:</u><br />
The likelihood is the <a href="https://en.wikipedia.org/wiki/Conditional_probability"  class="external-link" target="_blank" rel="noopener">conditional probability</a> of observing the evidence <strong>x</strong> given the hypothesis <strong>z</strong>.</p>
</li>
<li>
<p><u> P(x) $\rightarrow$ Marginal Likelihood / &ldquo;Model Evidence&rdquo;:</u><br />
This gives the <a href="https://en.wikipedia.org/wiki/Marginal_distribution"  class="external-link" target="_blank" rel="noopener">marginal distribution</a> of the evidence, i.e. the probability of the evidence without any hypotheses being considered. As this would be the same for all hypotheses, it does not factor into determining relevant probabilities of different hypotheses. The marginal distribution of a variable that is jointly distributed is the probability distribution of that variable when the values of the other variable are not considered. This is essentially a summaton over the joint probability distribution over all values of the other variable. The converse is also true:<br />
$$ p_{X} ( x_{i} ) = \sum\limits_{j} p(x_{i} , y_{j}) $$
$$ p_{Y} ( y_{j} ) = \sum\limits_{i} p(x_{i} , y_{j}) $$</p>
</li>
<li>
<p><u> P ( z $\mid$ x) $\rightarrow$ Posterior:</u><br />
The <strong>posterior</strong> is the conditional probability of a hypothesis z given evidence, after x is observed. Essentially this tells us how likely a hypothesis is given the observed evidence.</p>
</li>
</ul>
<h4 id="summary">
  Summary
  <a class="heading-link" href="#summary">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>Bayesian Inference has many applications in science and engineering, especially in the field of <a href="https://en.wikipedia.org/wiki/Deep_learning"  class="external-link" target="_blank" rel="noopener">Deep Learning</a>. Inference is particularly useful in <a href="https://en.wikipedia.org/wiki/Generative_model"  class="external-link" target="_blank" rel="noopener">Generative models</a> such as <a href="https://en.wikipedia.org/wiki/Variational_autoencoder"  class="external-link" target="_blank" rel="noopener">Variational Autoencoders</a>, where we seek the likelihood of a data point <strong>x</strong> conditioned on a latent representation <strong>z</strong>. First we must use Variational Inference to approximate the underlying distribution of our data given our input, $p(z \mid x)$, we can then sample a latent representation, <strong>z</strong> from our approximation of the distribution and then generate data points by conditioning the probability of our data point, <strong>x</strong> on the sampled latent representation, $p (x \mid z)$. This all seems very abstract for now however, this page only serves as a warmup and reference page as we explore concepts in variational inference in future blog posts.</p>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script>
  window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlbytes" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    
    document.addEventListener('themeChanged', function (e) { 
        if (document.readyState == 'complete') {
          DISQUS.reset({ reload: true, config: disqus_config });
        }
    });
</script>
        
        
        
        
        
        
      </footer>
    </article>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
    2025
    
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
