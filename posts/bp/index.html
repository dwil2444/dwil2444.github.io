<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="color-scheme" content="light dark">

    

    
    <meta name="description" content="Bayesian Inference Bayesian Inference is an approach to statistical inference which utilises Bayes&rsquo; theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:
$$ p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)} $$
Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:">
    <meta name="keywords" content="">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Bayesian Inference"/>
<meta name="twitter:description" content="Bayesian Inference Bayesian Inference is an approach to statistical inference which utilises Bayes&rsquo; theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:
$$ p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)} $$
Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:"/>

    <meta property="og:title" content="Bayesian Inference" />
<meta property="og:description" content="Bayesian Inference Bayesian Inference is an approach to statistical inference which utilises Bayes&rsquo; theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:
$$ p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)} $$
Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dwil2444.github.io/posts/bp/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-05-05T00:00:00+00:00" />


    <title>
  Bayesian Inference Â· home
</title>

    
      <link rel="canonical" href="https://dwil2444.github.io/posts/bp/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css" integrity="sha256-2f3b/&#43;byfmmYXcX&#43;BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin="anonymous" media="screen" />
    

    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <meta name="generator" content="Hugo 0.110.0">
  </head>

  
  
  <body class="preload-transitions colorscheme-light">
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      home
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/publications">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/teaching">Teaching</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/cv.pdf">CV</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://dwil2444.github.io/posts/bp/">
              Bayesian Inference
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-05-05T00:00:00Z">
                May 5, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              3-minute read
            </span>
          </div>
          
          
          
        </div>
      </header>

      <div>
        
        <h1 align="center">Bayesian Inference </h1>
<p><strong>Bayesian Inference</strong> is an approach to statistical inference which utilises Bayes&rsquo; theorem to provide updates for the probability of an outcome as new information becomes available. The mathematical formulation for Bayes theorem is quite ubiquituous and no doubt you have seen it before, however it is stated here for completeness:</p>
<p>$$
p (z \mid x) = \frac{p(x \mid z) \cdot p(z)}{p(x)}
$$</p>
<p>Simple right? Perhaps not so much to the unitiated to whom this equation may seem very strange and as such here is a breakdown of what these terms actually mean:</p>
<h5 id="key-terms">
  Key Terms
  <a class="heading-link" href="#key-terms">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h5>
<ul>
<li>
<p><u> Z $\rightarrow$ Hypothesis:</u><br />
<strong>Z</strong> represents any hypothesis whose probability may be affected by data.</p>
</li>
<li>
<p><u> X $\rightarrow$ Evidence:</u><br />
<strong>X</strong> represents new data that was not used in computing <strong>prior</strong> probability.</p>
</li>
<li>
<p><u> P(z) $\rightarrow$ Prior:</u><br />
The <strong>prior</strong> is the estimate of the probability of the hypothesis <strong>z</strong> before the evidence <strong>x</strong> is observed.</p>
</li>
<li>
<p><u> P(x $\mid$ z) $\rightarrow$ Likelihood:</u><br />
The likelihood is the <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> of observing the evidence <strong>x</strong> given the hypothesis <strong>z</strong>.</p>
</li>
<li>
<p><u> P(x) $\rightarrow$ Marginal Likelihood / &ldquo;Model Evidence&rdquo;:</u><br />
This gives the <a href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distribution</a> of the evidence, i.e. the probability of the evidence without any hypotheses being considered. As this would be the same for all hypotheses, it does not factor into determining relevant probabilities of different hypotheses. The marginal distribution of a variable that is jointly distributed is the probability distribution of that variable when the values of the other variable are not considered. This is essentially a summaton over the joint probability distribution over all values of the other variable. The converse is also true:<br />
$$ p_{X} ( x_{i} ) = \sum\limits_{j} p(x_{i} , y_{j}) $$
$$ p_{Y} ( y_{j} ) = \sum\limits_{i} p(x_{i} , y_{j}) $$</p>
</li>
<li>
<p><u> P ( z $\mid$ x) $\rightarrow$ Posterior:</u><br />
The <strong>posterior</strong> is the conditional probability of a hypothesis z given evidence, after x is observed. Essentially this tells us how likely a hypothesis is given the observed evidence.</p>
</li>
</ul>
<h4 id="summary">
  Summary
  <a class="heading-link" href="#summary">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>Bayesian Inference has many applications in science and engineering, especially in the field of <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a>. Inference is particularly useful in <a href="https://en.wikipedia.org/wiki/Generative_model">Generative models</a> such as <a href="https://en.wikipedia.org/wiki/Variational_autoencoder">Variational Autoencoders</a>, where we seek the likelihood of a data point <strong>x</strong> conditioned on a latent representation <strong>z</strong>. First we must use Variational Inference to approximate the underlying distribution of our data given our input, $p(z \mid x)$, we can then sample a latent representation, <strong>z</strong> from our approximation of the distribution and then generate data points by conditioning the probability of our data point, <strong>x</strong> on the sampled latent representation, $p (x \mid z)$. This all seems very abstract for now however, this page only serves as a warmup and reference page as we explore concepts in variational inference in future blog posts.</p>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlbytes" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
    integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
    integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    Â©
    
    2023
    
    Â·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

    </main>

    
      
      <script src="/js/coder.min.9cf2dbf9b6989ef8eae941ffb4231c26d1dc026bca38f1d19fdba50177d8a9ac.js" integrity="sha256-nPLb&#43;baYnvjq6UH/tCMcJtHcAmvKOPHRn9ulAXfYqaw="></script>
    

    

    

    

    

    

    

    

    
  </body>

</html>
